"""
Keyword Pre-Filter for LLM Contracts Research Pipeline.

Boolean scan that removes â‰ˆ70% noise while retaining >93% recall.
Combines LLM contract keywords with ML-style root-cause cues.
"""

import re
import logging
from typing import List, Dict, Set, Tuple, Any
from dataclasses import dataclass
from datetime import datetime

from ..common.models import RawPost, FilteredPost
from ..common.database import MongoDBManager, ProvenanceTracker

logger = logging.getLogger(__name__)


@dataclass
class FilterResult:
    """Result of keyword filtering."""
    passed: bool
    confidence: float
    matched_keywords: List[str]
    relevant_snippets: List[str]
    potential_contracts: List[str]
    filter_metadata: Dict[str, Any]


class KeywordPreFilter:
    """
    Keyword-based pre-filter for LLM contract research.

    Features:
    - LLM contract keywords (max_tokens, json schema, rate_limit, etc.)
    - ML-style root-cause cues from Khairunnesa et al.
    - Context-aware snippet extraction
    - Confidence scoring
    """

    def __init__(self, db_manager: MongoDBManager):
        """Initialize keyword pre-filter.

        Args:
            db_manager: MongoDB manager for storage
        """
        self.db = db_manager
        self.provenance = ProvenanceTracker(db_manager)

        # LLM Contract Keywords - focused on contract violations from research
        self.llm_contract_keywords = {
            # Core API parameters (from contract violations)
            'max_tokens', 'temperature', 'top_p', 'frequency_penalty',
            'presence_penalty', 'stop', 'stream', 'logprobs', 'logit_bias',
            'n', 'best_of', 'echo', 'suffix', 'context_length', 'context_limit',

            # JSON and schema violations (major category in research)
            'json_schema', 'response_format', 'function_calling', 'tools',
            'schema', 'structured_output', 'json_mode', 'parse_error',
            'json_parse', 'malformed_json', 'invalid_json', 'schema_validation',

            # Rate limiting and quotas (frequent violations)
            'rate_limit', 'quota', 'rpm', 'tpm', 'requests_per_minute',
            'tokens_per_minute', 'usage_quota', 'billing', 'rate_exceeded',
            'quota_exceeded', 'rate_limit_error', 'too_many_requests',

            # Error codes and patterns (API contract violations)
            'invalid_request', 'model_not_found', 'insufficient_quota',
            'context_length_exceeded', 'rate_limit_exceeded', 'timeout',
            'authentication_error', 'permission_denied', 'bad_request',
            'unauthorized', 'forbidden', 'server_error', 'service_unavailable',

            # Content policy violations (new category from research)
            'content_policy', 'usage_policy', 'content_filter', 'safety_filter',
            'policy_violation', 'flagged_content', 'moderation', 'content_moderation',

            # Token limit violations (very common)
            'token_limit', 'token_exceeded', 'context_overflow', 'input_too_long',
            'prompt_too_long', 'message_too_long', 'conversation_too_long',

            # Model-specific issues
            'model_name', 'model_id', 'engine', 'deployment_id',
            'fine_tuning', 'custom_model', 'base_model', 'model_error'
        }

        # ML-style root-cause cues from Khairunnesa et al.
        self.ml_root_cause_keywords = {
            # Data type issues
            'dtype', 'datatype', 'type_error', 'shape_mismatch', 'dimension',
            'tensor_shape', 'array_shape', 'ndarray', 'dtype_mismatch',

            # Preprocessing issues
            'preprocess', 'normalize', 'tokenize', 'encode', 'decode',
            'transform', 'clean', 'filter', 'split', 'batch',

            # Seed and reproducibility
            'seed', 'random_state', 'reproducible', 'deterministic',
            'random_seed', 'numpy_seed', 'torch_seed',

            # Memory and performance
            'memory_error', 'out_of_memory', 'cuda_error', 'gpu_memory',
            'memory_leak', 'performance', 'slow', 'timeout',

            # Version and compatibility
            'version_mismatch', 'compatibility', 'deprecated', 'upgrade',
            'downgrade', 'version_error', 'library_version'
        }

        # Error indicators
        self.error_indicators = {
            'error', 'exception', 'failed', 'fail', 'crash', 'bug',
            'issue', 'problem', 'trouble', 'broken', 'not_working',
            'doesnt_work', "doesn't work", 'help', 'fix', 'solve',
            'debug', 'traceback', 'stack_trace'
        }

        # Contract violation patterns (regex) - enhanced for LLM contracts
        self.contract_patterns = [
            # Parameter validation patterns (core contract violations)
            r'(?i)(max_tokens|temperature|top_p)\s*(must|should|cannot|error|invalid|exceeds?|limit)',
            r'(?i)(rate.?limit|quota).*(exceeded|error|reached|hit|violation|denied)',
            r'(?i)(context.?length|token.?limit).*(exceeded|too.?long|error|overflow|maximum)',
            r'(?i)(json|schema).*(invalid|error|malformed|wrong|parse|failed|validation)',
            r'(?i)(api.?key|token).*(invalid|expired|missing|error|unauthorized|forbidden)',

            # Content policy patterns (new from research)
            r'(?i)(content|usage).?policy.*(violation|violated|flagged|denied|rejected)',
            r'(?i)(safety|moderation).*(filter|blocked|flagged|violation)',
            r'(?i)(prompt|input|content).*(filtered|blocked|inappropriate|violation)',

            # Token/context limit patterns (very common)
            r'(?i)(context|token|input).*(limit|maximum|exceeded|overflow|too.?long)',
            r'(?i)(conversation|history).*(too.?long|exceeded|truncated)',
            r'(?i)maximum.?context.?length.*(exceeded|reached)',

            # Error code patterns (HTTP status codes)
            r'(?i)(400|401|403|429|500|502|503|504)\s*(error|status|code)',
            r'(?i)error.?code\s*:?\s*\d+',
            r'(?i)(BadRequest|Unauthorized|RateLimit|ServerError|InvalidRequest)',

            # Contract-specific error messages (precise language)
            r'(?i)(parameter|argument).*(required|missing|invalid|out.?of.?range)',
            r'(?i)(must|should|cannot).*(be|provide|specify|exceed|contain)',
            r'(?i)(expected|requires?).*(but|got|received|found|instead)',

            # Output format violations (common in LLM usage)
            r'(?i)(output|response).*(format|schema|structure).*(invalid|wrong|unexpected)',
            r'(?i)(failed|unable).*(parse|decode|extract).*(json|xml|yaml)',
            r'(?i)(model|llm).*(did.?not|failed.?to).*(follow|generate|produce)',

            # Function calling violations (tool use contracts)
            r'(?i)(function|tool).*(call|calling).*(error|failed|invalid|unknown)',
            r'(?i)(tool|function).*(not.?found|unavailable|missing|undefined)'
        ]

        # Compile regex patterns for efficiency
        self.compiled_patterns = [re.compile(
            pattern) for pattern in self.contract_patterns]

    async def filter_batch(
        self,
        batch_size: int = 1000,
        confidence_threshold: float = 0.3
    ) -> Dict[str, Any]:
        """Filter a batch of raw posts.

        Args:
            batch_size: Number of posts to process in this batch
            confidence_threshold: Minimum confidence to pass filter

        Returns:
            Batch processing statistics
        """
        stats = {
            'processed': 0,
            'passed': 0,
            'failed': 0,
            'high_confidence': 0,
            'keywords_matched': {},
            'processing_time': 0
        }

        start_time = datetime.utcnow()

        # Get unfiltered posts
        async for raw_post_dict in self.db.get_posts_for_filtering(batch_size=batch_size):
            try:
                # Convert to RawPost object
                raw_post = RawPost(
                    _id=str(raw_post_dict['_id']),
                    platform=raw_post_dict['platform'],
                    source_id=raw_post_dict['source_id'],
                    title=raw_post_dict.get('title', ''),
                    body_md=raw_post_dict.get('body_md', ''),
                    tags=raw_post_dict.get('tags', []),
                    labels=raw_post_dict.get('labels', [])
                )

                # Apply filter
                filter_result = self.apply_filter(raw_post)

                # Create FilteredPost
                filtered_post = FilteredPost(
                    raw_post_id=raw_post._id,
                    passed_keyword_filter=filter_result.passed,
                    matched_keywords=filter_result.matched_keywords,
                    filter_confidence=filter_result.confidence,
                    relevant_snippets=filter_result.relevant_snippets,
                    potential_contracts=filter_result.potential_contracts,
                    filter_timestamp=datetime.utcnow(),
                    filter_version="1.0.0"
                )

                # Save to database
                filtered_id = await self.db.save_filtered_post(filtered_post.to_dict())

                # Log provenance
                await self.provenance.log_transformation(
                    source_id=raw_post._id,
                    source_collection='raw_posts',
                    target_id=filtered_id,
                    target_collection='filtered_posts',
                    transformation_type='keyword_filter',
                    metadata=filter_result.filter_metadata
                )

                # Update stats
                stats['processed'] += 1
                if filter_result.passed:
                    stats['passed'] += 1
                    if filter_result.confidence >= 0.7:
                        stats['high_confidence'] += 1
                else:
                    stats['failed'] += 1

                # Track keyword usage
                for keyword in filter_result.matched_keywords:
                    stats['keywords_matched'][keyword] = stats['keywords_matched'].get(
                        keyword, 0) + 1

            except Exception as e:
                logger.error(
                    f"Error filtering post {raw_post_dict.get('_id', 'unknown')}: {str(e)}")
                continue

        stats['processing_time'] = (
            datetime.utcnow() - start_time).total_seconds()
        return stats

    def apply_filter(self, raw_post: RawPost) -> FilterResult:
        """Apply keyword filter to a single post.

        Args:
            raw_post: Raw post to filter

        Returns:
            FilterResult with pass/fail decision and metadata
        """
        # Combine all text content
        combined_text = f"{raw_post.title} {raw_post.body_md}"
        combined_text_lower = combined_text.lower()

        # Check for keywords
        matched_llm_keywords = self._find_keywords(
            combined_text_lower, self.llm_contract_keywords)
        matched_ml_keywords = self._find_keywords(
            combined_text_lower, self.ml_root_cause_keywords)
        matched_error_keywords = self._find_keywords(
            combined_text_lower, self.error_indicators)

        all_matched_keywords = matched_llm_keywords + \
            matched_ml_keywords + matched_error_keywords

        # Check for contract patterns
        contract_matches = self._find_contract_patterns(combined_text)

        # Check tags and labels
        tag_matches = self._check_tags_and_labels(
            raw_post.tags + raw_post.labels)

        # Calculate confidence score
        confidence = self._calculate_confidence(
            matched_llm_keywords,
            matched_ml_keywords,
            matched_error_keywords,
            contract_matches,
            tag_matches,
            combined_text
        )

        # Extract relevant snippets
        relevant_snippets = self._extract_snippets(
            combined_text,
            all_matched_keywords + [match[0] for match in contract_matches]
        )

        # Identify potential contracts
        potential_contracts = self._identify_potential_contracts(
            combined_text,
            matched_llm_keywords,
            contract_matches
        )

        # More restrictive decision logic: require stronger signals for LLM contracts
        passed = (
            confidence >= 0.5 or  # Higher confidence threshold
            # Require both LLM keywords AND error indicators (stronger signal)
            (len(matched_llm_keywords) >= 2 and len(matched_error_keywords) >= 1) or
            len(contract_matches) >= 2 or  # Multiple contract patterns
            # High-quality tag combinations
            (len(tag_matches) >= 2 and len(matched_llm_keywords) >= 1)
        )

        # Filter metadata
        filter_metadata = {
            'llm_keywords_count': len(matched_llm_keywords),
            'ml_keywords_count': len(matched_ml_keywords),
            'error_keywords_count': len(matched_error_keywords),
            'contract_patterns_count': len(contract_matches),
            'tag_matches_count': len(tag_matches),
            'text_length': len(combined_text),
            'decision_factors': {
                'confidence_threshold': confidence >= 0.3,
                'llm_plus_errors': len(matched_llm_keywords) > 0 and len(matched_error_keywords) > 0,
                'contract_patterns': len(contract_matches) > 0,
                'relevant_tags': len(tag_matches) > 0
            }
        }

        return FilterResult(
            passed=passed,
            confidence=confidence,
            matched_keywords=all_matched_keywords,
            relevant_snippets=relevant_snippets,
            potential_contracts=potential_contracts,
            filter_metadata=filter_metadata
        )

    def _find_keywords(self, text: str, keyword_set: Set[str]) -> List[str]:
        """Find matching keywords in text."""
        matches = []
        for keyword in keyword_set:
            # Handle both exact matches and word boundaries
            if keyword in text:
                # Check if it's a word boundary match for better precision
                if re.search(r'\b' + re.escape(keyword) + r'\b', text):
                    matches.append(keyword)
                elif '_' in keyword and keyword in text:
                    # For snake_case keywords, allow exact substring match
                    matches.append(keyword)
        return matches

    def _find_contract_patterns(self, text: str) -> List[Tuple[str, int, int]]:
        """Find contract violation patterns using regex.

        Returns:
            List of (matched_text, start_pos, end_pos) tuples
        """
        matches = []
        for pattern in self.compiled_patterns:
            for match in pattern.finditer(text):
                matches.append((match.group(), match.start(), match.end()))
        return matches

    def _check_tags_and_labels(self, tags_and_labels: List[str]) -> List[str]:
        """Check for relevant tags and labels."""
        relevant_tags = []
        llm_tag_patterns = [
            'openai', 'gpt', 'claude', 'anthropic', 'langchain',
            'api', 'bug', 'error', 'rate-limit', 'timeout', 'json'
        ]

        for tag in tags_and_labels:
            tag_lower = tag.lower()
            for pattern in llm_tag_patterns:
                if pattern in tag_lower:
                    relevant_tags.append(tag)
                    break

        return relevant_tags

    def _calculate_confidence(
        self,
        llm_keywords: List[str],
        ml_keywords: List[str],
        error_keywords: List[str],
        contract_matches: List[Tuple[str, int, int]],
        tag_matches: List[str],
        text: str
    ) -> float:
        """Calculate confidence score for the filter decision."""

        # Base score components
        # Up to 0.5 for LLM keywords
        llm_score = min(len(llm_keywords) * 0.2, 0.5)
        # Up to 0.2 for ML keywords
        ml_score = min(len(ml_keywords) * 0.1, 0.2)
        # Up to 0.2 for error keywords
        error_score = min(len(error_keywords) * 0.1, 0.2)
        pattern_score = min(len(contract_matches) * 0.3,
                            0.6)  # Up to 0.6 for patterns
        tag_score = min(len(tag_matches) * 0.15, 0.3)  # Up to 0.3 for tags

        # Combination bonuses
        combination_bonus = 0.0
        if len(llm_keywords) > 0 and len(error_keywords) > 0:
            combination_bonus += 0.2  # LLM + error is strong signal

        if len(contract_matches) > 0 and len(llm_keywords) > 0:
            combination_bonus += 0.15  # Contract patterns + LLM keywords

        # Text quality factors
        text_length = len(text)
        if text_length > 100:  # Prefer longer, more descriptive posts
            length_bonus = min((text_length - 100) / 1000, 0.1)
        else:
            length_bonus = -0.1  # Penalize very short posts

        # Calculate final confidence
        confidence = llm_score + ml_score + error_score + \
            pattern_score + tag_score + combination_bonus + length_bonus

        return min(max(confidence, 0.0), 1.0)  # Clamp to [0, 1]

    def _extract_snippets(self, text: str, keywords: List[str], context_size: int = 100) -> List[str]:
        """Extract relevant snippets around keywords."""
        snippets = []
        text_lower = text.lower()

        for keyword in keywords[:10]:  # Limit to top 10 keywords
            keyword_lower = keyword.lower()
            start_pos = text_lower.find(keyword_lower)

            if start_pos != -1:
                # Extract context around the keyword
                snippet_start = max(0, start_pos - context_size)
                snippet_end = min(len(text), start_pos +
                                  len(keyword) + context_size)
                snippet = text[snippet_start:snippet_end].strip()

                if len(snippet) > 20:  # Only keep meaningful snippets
                    snippets.append(snippet)

        return snippets[:5]  # Return top 5 snippets

    def _identify_potential_contracts(
        self,
        text: str,
        llm_keywords: List[str],
        contract_matches: List[Tuple[str, int, int]]
    ) -> List[str]:
        """Identify potential contract clauses in the text."""
        contracts = []

        # Extract sentences containing LLM keywords
        sentences = re.split(r'[.!?]+', text)
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 20:  # Meaningful sentence
                sentence_lower = sentence.lower()
                for keyword in llm_keywords:
                    if keyword.lower() in sentence_lower:
                        contracts.append(sentence)
                        break

        # Add contract pattern matches
        for match_text, _, _ in contract_matches:
            if len(match_text) > 10:
                contracts.append(match_text)

        return contracts[:3]  # Return top 3 potential contracts

    async def get_filter_statistics(self) -> Dict[str, Any]:
        """Get filtering statistics from the database."""
        stats = {}

        # Overall filter stats
        total_filtered = await self.db.count_documents('filtered_posts')
        passed_filter = await self.db.count_documents('filtered_posts', {'passed_keyword_filter': True})
        failed_filter = total_filtered - passed_filter

        stats['overall'] = {
            'total_filtered': total_filtered,
            'passed': passed_filter,
            'failed': failed_filter,
            'pass_rate': (passed_filter / total_filtered * 100) if total_filtered > 0 else 0
        }

        # Confidence distribution
        high_confidence = await self.db.count_documents('filtered_posts', {
            'filter_confidence': {'$gte': 0.7},
            'passed_keyword_filter': True
        })
        medium_confidence = await self.db.count_documents('filtered_posts', {
            'filter_confidence': {'$gte': 0.4, '$lt': 0.7},
            'passed_keyword_filter': True
        })
        low_confidence = await self.db.count_documents('filtered_posts', {
            'filter_confidence': {'$lt': 0.4},
            'passed_keyword_filter': True
        })

        stats['confidence_distribution'] = {
            'high': high_confidence,
            'medium': medium_confidence,
            'low': low_confidence
        }

        return stats
